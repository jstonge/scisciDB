// How to get started with mongoDB using `mongosh`. 
//
// I currently use the vscode plug-in to interact with mongoDB. 
// See https://code.visualstudio.com/docs/azure/mongodb.
// I like it b/c it is a middle between mongoDB Compass and the commandline.
//
// Key refs:
//  - `install mongosh:` https://www.mongodb.com/docs/mongodb-shell/install/
//  - `data modeling:` https://www.mongodb.com/docs/manual/core/data-modeling-introduction/
//  - `operators`: https://www.mongodb.com/docs/manual/reference/operator/query/
//  - `Monitoring DB`: https://www.percona.com/blog/monitoring-mongodb-collection-stats-with-percona-monitoring-and-management/
//  - `Update documents`: https://www.mongodb.com/docs/mongodb-shell/crud/update/
//  - `Queries`:
//     - https://www.mongodb.com/docs/manual/tutorial/query-array-of-documents/
//  - `indexes`: 
//     - https://www.mongodb.com/basics/mongodb-index
//     - https://www.mongodb.com/docs/manual/indexes/
//     - https://www.percona.com/blog/2018/09/04/mongodb-index-usage-and-mongodb-explain-part-1/
//     - https://www.percona.com/blog/2018/09/06/mongodb-investigate-queries-with-explain-index-usage-part-2/
//     - https://www.bmc.com/blogs/mongodb-indexes/
//  - `best practices:`
//     - https://www.mongodb.com/basics/best-practices


// Connect to papersDB
use('papersDB');

// Looking at collections within our DB
show collections;

// Look at already existing indexes
 db.metadata.getIndexes()

// `snippet` is a collections of snippets that can be very useful, e.g. 
// snippet install analyze-schema (https://github.com/mongodb-labs/mongosh-snippets)
// Analyze schema. Takes a while, but gives you a nice summary of the schema.
schema(db.pdf_parses);

// estimate count document based on year is super quick
db.metadata.estimatedDocumentCount()

// you can 'explain' queries. Super useful to understand how mongoDB works and query performances.

var exp = db.metadata.explain("executionStats")
exp.find({title: "Scale-free networks are rare"}) // executionTimeMillis: 14827; totalDocsExamined: 19,786,006
db.metadata.createIndex({year: -1}); // create index based on age
exp.find({title: "Scale-free networks are rare", year: 2018}).limit(1) // executionTimeMillis: 3851; totalKeysExamined: 786,497

// Dropping indexes
db.metadata.dropIndex("year_-1")

// How to use operators
db.metadata.findOne({year: {$gt: 2015, $lt: 2020})

// ------------------------------ USEFUL QUERIES ------------------------------ //


// 1-find papers based on `paper_id`

db.pdf_parses.findOne({ paper_ID: "77497072"});

// 2-find papers based on `paper_id` and year

db.metadata.findOne({ year: {$gt: 2015, $lt: 2022}, paper_id: "f1b4361a1978e93018c5fdfe4856250152676ffb" })


// 3-Query papers with `body_text`
// see https://stackoverflow.com/questions/14789684/find-mongodb-records-where-array-field-is-not-empty

db.pdf_parses.findOne({ body_text: { $gt: true, $type: 'array', $ne: [] }})

// 4-Query authors

db.metadata.findOne({ 'authors.0.first': "Aaron" })
db.metadata.findOne({ 'authors.first': "Aaron" })
db.metadata.findOne({ 'authors.last': "Clauset" })

// -------------------------- SQL v. mongoDB SHOWDOWN -------------------------- //

// 1-finding people
db.metadata.aggregate({ $filter : { authors.last : { $eq : "Clauset" } } });

SELECT * FROM metadata
WHERE authors.last = "Clauset";


// ----------------------- USEFUL AGGREGATED QUERIES ------------------------- //


// Find duplicated rows (not sure it is working yet)

// const aggregation = [
//     {"$group" : { "_id": "$paper_id", "count": { "$sum": 1 } } },
//     {"$match": {"_id" :{ "$ne" : null } , "count" : {"$gt": 1} } }, 
//     {"$project": {"paper_id" : "$_id", "_id" : 0} }
// ]

// db.pdf_parses.aggregate(aggregation);


// -------------------------- DOCUMENTS EMBEDDINGS ---------------------------- //


// Embed one collection into a second collection 
// not sure it is working yet, this is a chatgpt answer

db.collection1.update({name: "John Doe"}, {$set: {address: db.collection2.findOne({address: "123 Main St"})}})


// ------------------------------ CREATING INDEX ------------------------------ //


// Create index based on descending year
db.metadata.createIndex({year: -1});

// From Percona, this allows to improve all the queries that find documents with a condition and the year field, like the following:
db.metadata.find( { year : 2018 } ) 
db.metadata.find( { title : "Scale-free networks are rare", year : 2018 } )
db.metadata.find( { year : { $gt : 2020} } )
db.metadata.find().sort( { year: -1} ).limit(10)

// Create index based on authors (Multikey indexes; Not great)

db.metadata.createIndex( { authors: 1 } )
db.metadata.find( { authors.last: "Clauset" } )

// Create index based on year and `has_body_text` (include a Partial indexes and Unique)
// In order for the partial index to be used the queries must contain a condition on the year and body_text field.
db.metadata.createIndex(
   { "paper_id": 1 },
   { unique: true },
   { partialFilterExpression: { year : { $gt: 2018 }, body_text: { $gt: true, $type: 'array', $ne: [] } } }
)

db.metadata.find( { paper_id: "77490322", year: { $gt: 2018}, body_text: { $gt: true, $type: 'array', $ne: []} } )

// Create index based on year (asc) and bounded by 1950-60

exp.find({"year": {$gte: 1950, $lte: 1960}, "paper_id": "77490322"}).limit(1) // executionTimeMillis: 360429; totalKeysExamined: 2024098
db.metadata.createIndex({year:1}, { partialFilterExpression: { year : { $gte: 1950, $lte: 1960 } } });
exp.find({"year": {$gte: 1950, $lte: 1960}, "paper_id": "77490322"}).limit(1) // executionTimeMillis: 68676; totalKeysExamined: 406162

// ---------------------------- UPDATING DOCUMENTS ------------------------------ //




// -------------------------- Examples using functions -------------------------- //


// also
// https://stackoverflow.com/questions/27039083/mongodb-move-documents-from-one-collection-to-another-collection

function insertBatch(collection, documents) {
  var bulkInsert = collection.initializeUnorderedBulkOp();
  var insertedIds = [];
  var id;
  documents.forEach(function(doc) {
    id = doc._id;
    // Insert without raising an error for duplicates
    bulkInsert.find({_id: id}).upsert().replaceOne(doc);
    insertedIds.push(id);
  });
  bulkInsert.execute();
  return insertedIds;
}

function deleteBatch(collection, documents) {
  var bulkRemove = collection.initializeUnorderedBulkOp();
  documents.forEach(function(doc) {
    bulkRemove.find({_id: doc._id}).removeOne();
  });
  bulkRemove.execute();
}

function moveDocuments(sourceCollection, targetCollection, filter, batchSize) {
  print("Moving " + sourceCollection.find(filter).count() + " documents from " + sourceCollection + " to " + targetCollection);
  var count;
  while ((count = sourceCollection.find(filter).count()) > 0) {
    print(count + " documents remaining");
    sourceDocs = sourceCollection.find(filter).limit(batchSize);
    idsOfCopiedDocs = insertBatch(targetCollection, sourceDocs);

    targetDocs = targetCollection.find({_id: {$in: idsOfCopiedDocs}});
    deleteBatch(sourceCollection, targetDocs);
  }
  print("Done!")
}

